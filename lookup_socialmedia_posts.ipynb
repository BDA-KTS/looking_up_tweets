{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "HojYv92k8CxA",
   "metadata": {
    "id": "HojYv92k8CxA"
   },
   "source": [
    "# Semantic search over social media posts (tweets)\n",
    "\n",
    "The method implements semantic search over a collection of social media posts e.g., tweets, and returns the most similar posts to the search query. It uses a pretrained language model (embeddings) to determine the posts closest to the query text using cosine similarity and returns the ranked results.  \n",
    "\n",
    "The script is divided into two main sections:\n",
    "\n",
    "__1. Getting the Document Embeddings:__ This section processes social media posts and converts them into numerical embeddings.\n",
    "\n",
    "__2. Looking Up posts:__ Here, we use cosine similarity to find social media posts that are most similar to the user-provided search query.\n",
    "\n",
    "*Some utility functionalities regarding data loading, preprocessing, tokenization are in the `utils.py` file.*\n",
    "\n",
    "We use Twitter samples downloaded from the NLTK library to demonstrate this method. You can download it here:\n",
    "\n",
    "```\n",
    "import nltk\n",
    "nltk.download('twitter_samples')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f47f530-3d08-4548-aa46-163c67fc7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal (utils.py) and external resources\n",
    "from utils import (load_data, clean_posts, tokenize_posts, \n",
    "cosine_similarity, read_configurations, write_output)\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3775078-5731-4b47-91e1-a624ad3e990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For predictable random numbers in reuse\n",
    "import random\n",
    "random.seed(13)\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2eb4259-0c4e-4e8c-a6bd-4e4990e24b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ifpreprocess': True,\n",
       " 'top-k': 5,\n",
       " 'input_query_filepath': '/data/input_queries.txt',\n",
       " 'output_filepath': '/data/output.json',\n",
       " 'posts_filepath': '/socialmedia_posts/corpora/twitter_samples/tweets.20150430-223406.json'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurations = read_configurations(\"/config.json\")\n",
    "configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38699fac-a1c4-464f-8439-44e84e8e9633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['social media', 'women', 'election'],\n",
       " ['RT @KirkKus: Indirect cost of the UK being in the EU is estimated to be costing Britain £170 billion per year! #BetterOffOut #UKIP',\n",
       "  'VIDEO: Sturgeon on post-election deals http://t.co/BTJwrpbmOY',\n",
       "  'RT @LabourEoin: The economy was growing 3 times faster on the day David Cameron became Prime Minister than it is today.. #BBCqt http://t.co…'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read input queries\n",
    "\n",
    "\n",
    "ls_input_queries, ls_posts = load_data(configurations['input_query_filepath'], \n",
    "                            configurations['posts_filepath'])\n",
    "ls_input_queries[:3], ls_posts[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iqbAWxNiD4Jr",
   "metadata": {
    "id": "iqbAWxNiD4Jr"
   },
   "source": [
    "\n",
    "## 1 - Getting the Document Embeddings\n",
    "\n",
    "###  The Word Embeddings Data for English Words\n",
    "\n",
    "The full dataset for English embeddings is about 3.64 gigabytes. To prevent the workspace from\n",
    "crashing, we've extracted a subset of the embeddings for the words that you'll\n",
    "use in this Tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83648f22-d092-42df-bef3-0c10508e5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "en_embeddings = pickle.load(open(\"./embeddings/en_embeddings.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GQ8FFDW58CxI",
   "metadata": {
    "id": "GQ8FFDW58CxI"
   },
   "source": [
    "\n",
    "\n",
    "### Bag-of-words (BOW) Document Models\n",
    "Text documents are sequences of words.\n",
    "* The ordering of words makes a difference. For example, sentences \"Apple pie is\n",
    "better than pepperoni pizza.\" and \"Pepperoni pizza is better than apple pie\"\n",
    "have opposite meanings due to the word ordering.\n",
    "* However, for some applications, ignoring the order of words can allow\n",
    "us to train an efficient and still effective model. *In this method, we are averaging the word vectors in a post i.e., losing their position related information*\n",
    "* This approach is called Bag-of-words document model.\n",
    "\n",
    "### Document Embeddings\n",
    "* Document embedding is created by summing up the embeddings of all words\n",
    "in the document.\n",
    "* If we don't know the embedding of some word, we can ignore that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a17fb7d8-caca-4400-a802-d2255516ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess social media posts by removing urls, hashtags, stickers and other unwanted patterns.\n",
    "\n",
    "if configurations[\"ifpreprocess\"]:\n",
    "    posts = clean_posts(ls_posts)\n",
    "\n",
    "# Tokenize, stem and return clean tokens\n",
    "tokenized_posts = tokenize_posts(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geJAOUKx8CxI",
   "metadata": {
    "id": "geJAOUKx8CxI"
   },
   "source": [
    "<a name=\"1-1-4\"></a>\n",
    "\n",
    "### Function 'get_document_embedding'\n",
    "* The function `get_document_embedding()` encodes entire document as a \"document\" embedding.\n",
    "* It takes in a document (as a string) and a dictionary, `en_embeddings`\n",
    "* It processes the document, and looks up the corresponding embedding of each word.\n",
    "* It then sums them up and returns the sum of all word vectors of that processed tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9hUI39rP8CxJ",
   "metadata": {
    "id": "9hUI39rP8CxJ"
   },
   "outputs": [],
   "source": [
    "#Computer doc embedding vector i.e., average of all its word embeddings\n",
    "def compute_doc_embedding(post):\n",
    "    doc_embedding = np.zeros(300)\n",
    "    for token in post:\n",
    "        # add the word embedding to the running total for the document embedding\n",
    "        doc_embedding += en_embeddings.get(token, np.zeros(300))\n",
    "        doc_embedding = np.divide(doc_embedding, len(post))\n",
    "    return doc_embedding\n",
    "\n",
    "# This method reads a social media posts anc returns its embedded vector i.e., the average of embedded vectors of all its words\n",
    "def vectorize_posts(posts, en_embeddings):\n",
    "    '''\n",
    "    Input:\n",
    "        - tweet: a string\n",
    "        - en_embeddings: a dictionary of word embeddings\n",
    "    Output:\n",
    "        - doc_embedding: sum of all word embeddings in the tweet\n",
    "    '''\n",
    "\n",
    "    # the dictionary's key is an index (integer) that identifies a specific tweet\n",
    "    # the value is the document embedding for that document\n",
    "    ind2Doc_dict = {}\n",
    "\n",
    "    # this is list that will store the document vectors\n",
    "    document_vec_l = []\n",
    "    \n",
    "    posts_embeddings = []\n",
    "    i = 0\n",
    "    for post in posts:\n",
    "        doc_embedding = compute_doc_embedding(post)\n",
    "\n",
    "        # save the document embedding into the ind2Tweet dictionary at index i\n",
    "        ind2Doc_dict[i] = doc_embedding\n",
    "        i += 1\n",
    "        # append the document embedding to the list of document vectors\n",
    "        document_vec_l.append(doc_embedding)\n",
    "\n",
    "        # convert the list of document vectors into a 2D array (each row is a document vector)\n",
    "        document_vec_matrix = np.vstack(document_vec_l)\n",
    "\n",
    "    return document_vec_matrix, ind2Doc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EKzzc5-y8CxL",
   "metadata": {
    "id": "EKzzc5-y8CxL"
   },
   "source": [
    "<a name=\"1-1-5\"></a>\n",
    "### Function 'Vectorize_posts'\n",
    "\n",
    "#### Store all document vectors into a dictionary\n",
    "Now, let's store all the posts embeddings into a dictionary.\n",
    "Implement `vectorize_posts()`\n",
    "\n",
    "The following cell computes embedding (Posts x vector) matirx having each post represented with the standard 300 size vector. It may take *5-10mins* for *20,000 posts* on regular PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e3ee01-00ff-46d0-a0f3-6e474b3cbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokenized documents into their 300vector embeddings\n",
    "# The word vectors are averaged for each document\n",
    "\n",
    "posts_vec_matrix, ind2Doc_dict = vectorize_posts(tokenized_posts,en_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b971ce9e-a591-406d-af54-53e7b3fa092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dictionary 20000\n",
      "shape of document_vecs (20000, 300)\n"
     ]
    }
   ],
   "source": [
    "# ind2Doc dictionary and matrix of posts vectors generated\n",
    "\n",
    "print(f\"length of dictionary {len(ind2Doc_dict)}\")\n",
    "print(f\"shape of document_vecs {posts_vec_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8G8lDqU8CxM",
   "metadata": {
    "id": "c8G8lDqU8CxM"
   },
   "source": [
    "\n",
    "## 2 - Looking up the Posts\n",
    "\n",
    "Now you have a vector of dimension (m,d) where `m` is the number of posts\n",
    "(20,000) and `d` is the dimension of the embeddings (300).  \n",
    "\n",
    "Now we will calculate post similarities for the query inputs using cosine similarity over the entire posts vector matix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70228993-5690-4d14-a5fb-1cafe28ca992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['social', 'media'], ['women'], ['election']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess queries.\n",
    "\n",
    "if configurations[\"ifpreprocess\"]:\n",
    "    ls_input_queries = clean_posts(ls_input_queries)\n",
    "\n",
    "# Tokenize, stem and return clean tokens\n",
    "tokenized_queries = tokenize_posts(ls_input_queries)\n",
    "tokenized_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f8166e3-5ac6-4784-b793-eeab074a7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get top K similar posts for all query items\n",
    "\n",
    "query_posts_similarities = {}\n",
    "for query in tokenized_queries:\n",
    "    query_embedding = compute_doc_embedding(query)\n",
    "    cosine_score = cosine_similarity(posts_vec_matrix, query_embedding)\n",
    "    top_indices = np.argsort(cosine_score)[-configurations[\"top-k\"]:][::-1]\n",
    "    query_str = ' '.join(query)\n",
    "    query_posts_similarities[query_str] = []\n",
    "    top_posts = []\n",
    "    for idx in top_indices:\n",
    "        top_posts.append({'post ID': str(idx),\n",
    "                          'post text': ls_posts[idx], \n",
    "                          \"sim score\": str(cosine_score[idx])})\n",
    "    query_posts_similarities[query_str] = top_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2e536f1-dcbd-4df1-b00c-13278c9f870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"social media\": [{\"post ID\": \"13567\", \"post text\": \"There\\'s something a bit \\\\\"dad dancing\\\\\" about the way the Tories try to electioneer via social media https://t.co/WH0cmv76VD\", \"sim score\": \"0.9372139191497816\"}, {\"post ID\": \"9732\", \"post text\": \"It\\'s extremely comforting to know that the power of mainstream media has been diluted by social media? #SNP\", \"sim score\": \"0.9371564729455584\"}, {\"post ID\": \"18324\", \"post text\": \"@mmaher70 @RichardJMurphy So why cant they defend the position thats just total incompetence constantly allow Tories to set agenda esp media\", \"sim score\": \"0.918129503287474\"}, {\"post ID\": \"13807\", \"post text\": \"RT @599tb: UKIP treated very differently by media #AskNigelFarage http://t.co/pLxsraTDTJ\", \"sim score\": \"0.9179315218984065\"}, {\"post ID\": \"14961\", \"post text\": \"RT @599tb: UKIP treated very differently by media #AskNigelFarage http://t.co/pLxsraTDTJ\", \"sim score\": \"0.9179315218984065\"}], \"women\": [{\"post ID\": \"287\", \"post text\": \"RT @macplus4: And. Miliband stumbled. Much bigger issues to discuss - NHS, mental health, foodbanks, homelessness, usual cuts to women &amp; ch\\\\u2026\", \"sim score\": \"0.9999048991755727\"}, {\"post ID\": \"2902\", \"post text\": \"Pigs sweat, men perspire  https://t.co/6ZIU37HYPh\", \"sim score\": \"0.7674937266310939\"}, {\"post ID\": \"4592\", \"post text\": \"@NRKesp1 \\\\nD\\\\u00e5 ser det m\\\\u00f8rkt ut for han...\\\\nVerre blir det om det blir sj\\\\u00f8lstyre og for England ?\\\\nTory kan tape men likevel vinne...\", \"sim score\": \"0.7657890410727743\"}, {\"post ID\": \"1972\", \"post text\": \"SNP now entrusts political polls to till girls. #snpout  https://t.co/U4EqIL7MV9\", \"sim score\": \"0.6339039759462265\"}, {\"post ID\": \"1872\", \"post text\": \"@alisonthewliss SNP now entrusts political polls to till girls. #snpout\", \"sim score\": \"0.6339039759462265\"}], \"election\": [{\"post ID\": \"19237\", \"post text\": \"#ELECTION2015  https://t.co/WgCyxkkAkc\", \"sim score\": \"0.9999999995861624\"}, {\"post ID\": \"14156\", \"post text\": \"#NigelFarage #UKIP #Election2015 http://t.co/oyr8o5aJCv\", \"sim score\": \"0.99999999834465\"}, {\"post ID\": \"3134\", \"post text\": \"@MarkDiStef Haha this is hilarious &amp; brilliant. Twitter with politicians is so empty. #onmessage #tories #election http://t.co/TloIFHijCU\", \"sim score\": \"0.9999999981778775\"}, {\"post ID\": \"1399\", \"post text\": \"RT @MPH1982: #edmiliband #miliband #therock #election2015 https://t.co/3VxgBE3t4q\", \"sim score\": \"0.9999999962754627\"}, {\"post ID\": \"979\", \"post text\": \"RT @MPH1982: #edmiliband #miliband #therock #election2015 https://t.co/3VxgBE3t4q\", \"sim score\": \"0.9999999962754627\"}]}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(query_posts_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3ca3d7d-998f-4603-ada7-87d13a149d27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Write output in json format\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mwrite_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfigurations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_filepath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_posts_similarities\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\projects\\MHcontent\\lookup_socialmedia_posts\\utils.py:35\u001b[0m, in \u001b[0;36mwrite_output\u001b[1;34m(output_filepath, query_posts_similarities)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outputfile:\n\u001b[0;32m     34\u001b[0m     outputfile\u001b[38;5;241m.\u001b[39mwrite(query_posts_similarities)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mfile\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "# Write output in json format\n",
    "write_output(configurations['output_filepath'], json.dumps(query_posts_similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7266f7-df59-496c-9e43-af251abbcc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
